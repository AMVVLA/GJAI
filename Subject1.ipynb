{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Subject1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOsmWZ0yEvYBDb/rdIKJwb5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AMVVLA/GJAI/blob/master/Subject1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GetgQYj-lPMj",
        "colab_type": "text"
      },
      "source": [
        "# 1주차 과제 \n",
        "\n",
        "* ## 언어\n",
        "  * ### 파파고\n",
        "2016년 10월 16일에 선보인 딥 러닝 기반의 번역기. Naver Labs에서 자체 개발한 인공신경망(Artificial Neural Network) 기반으로 인공신경망 번역(NMT·Neural Machine Translation) 기술을 사용하고 있다.\n",
        "NMT는 인공지능(AI)이 문장을 통째로 번역한다. 문장 단위 번역이 가능한 이유는 인공신경망이 문장 정보를 가상공간의 특정 지점을 의미하는 벡터(좌표값)로 변환하기 때문이다. 가령 '사람'이란 단어를 '[a, b, c, …, x, z]' 형태로 인식하는 것이다. 벡터에는 단어, 구절, 어순 등의 정보가 전부 들어있기 때문에 문맥을 이해한 문장 단위 번역이 가능하다. 인공신경망은 비슷한 의미를 담은 문장들을 서로 가까운 공간에 배치한다. 네이버의 번역 앱 '파파고'에 적용된 N2MT(Naver NMT) 기술은 1000차원 벡터를 활용한다. 네이버는 입력용 한글 문장과 출력용 영어 문장으로 이뤄진 학습 데이터를 활용해 인공신경망을 학습시켰다. 다만 개발자들은 인공신경망이 변환한 1000차원상 벡터의 좌표값 하나하나가 어떤 의미를 담고 있는지 알 수 없다. 인간이 이해할 수 없는 영역이 존재하는 건 NMT 기술의 장점이자 단점이다.\n",
        "\n",
        "\n",
        "* ## 음성\n",
        "  * ### Siri\n",
        "애플의 인공지능 개인 비서 응용 프로그램 Siri는 딥러닝을 사용하고 있다.\n",
        "기존의 인공신경망 기술은 사람의 실제 신경망을 구현하는 데에 있어 복잡성과 규모에 한계가 있었다. 반면 딥러닝 기술은 얕고 단순한 기존 인공신경망의 한계를 극복하고 보완한 ‘심층 신경망’ 기계 학습 알고리즘이다. 이 딥러닝 알고리즘은 음성 데이터의 입력, 각 모델들의 특징벡터 추출, 출력까지 복잡한 ‘맵핑(mapping)’ 과정이 이전보다 훨씬 빠르고 정확하도록 만들어준다.\n",
        "음성신호와 같은 연속적인 데이터를 모델링하는 방법으론 전통적으로 HMM(Hidden Marcov Model, 은닉마르코프 모델)이 있었다. HMM은 음성신호의 변동을 확률 변수로 취급해 주어진 음성의 문자열을 찾아낸다. 하지만 이는 확률에 기반하므로 예외가 많이 발생한다는 단점이 있다. 그 돌파구로 현재의 음성인식기술은 정확성이 높은 딥러닝 기술과 HMM 기술을 함께 활용하고 있다. 딥러닝 기술은 HMM으로 대상을 만들어 학습하고 딥러닝으로 모델링하는 방법을 이용한다. \n",
        "\n",
        "* ## 이미지\n",
        "  * ### Waifu 2x\n",
        "딥 러닝을 통해 배운 것을 토대로, Image Super-Resolution Using Deep Convolutional Networks 서비스를 응용하여 2D 그림의 해상도를 늘려주는 해상도 복원 서비스를 제공하는 사이트이다. 반복된 이미지 처리 CNN 학습을 기초로 발전된 이미지 및 동영상 알고리즘을 사용하면서, 받은 이미지를 다시 리사이징해서 그린다는 표현이 더 맞을 정도로 놀라운 복원력을 자랑한다.\n",
        "보통 평소에 사용한 필터를 컴퓨터 수식으로 나타내면 부정방정식이 되어버리는데, 이 결과값의 변수가 너무 많아진다는 점이 최대의 난적이었다. 하지만 어떻게든 컴퓨터는 기존의 정보를 활용해 픽셀을 채워넣어야 했고, 이것이 초창기 딥 러닝 알고리즘의 기본 목적이 되었다.\n",
        "이 비어있는 조각을 Convolutional Neural Network(CNN)를 사용해서 픽셀 공간을 계산하겠다는 이론을 제시했고, CNN은 그림에서 점, 선, 면 등의 요소를 추출해내는 성질을 가지고 있는데, 이를 바탕으로 손실된 디테일에 원래 어떤 내용이 있어야 할지를 스스로 판단해서 복원한다는 것. 한마디로 이미지를 받았다면 확대한 만큼 딥 러닝으로 부정방정식 연산과 이미지 배치열을 통해 배운 내용으로 채워넣는 방식이다.\n",
        "\n",
        "* ## 자율주행\n",
        "  * ### 테슬라 오토파일럿\n",
        "테슬라는 딥러닝을 위한 방대한 데이터를 수집하기 위하여 이미 판매된 자동차의 운전자들로부터 데이터를 수집할 수 있는 시스템을 구축하였다. 딥러닝을 이용할 경우 데이터의 양이 얼마나 많은지가 매우 중요한 역할을 하는데, 웨이모같은 다른 자율 주행 개발 회사가 설립 이후 모아온 총 데이터의 자동차 운행거리가 약 2천2백만km인 상황에서 테슬라는 단, 하루에도 그런 운행거리의 데이터를 수집하는 것이 가능하다. 2021년 말까지 테슬라 자동차는 약 42억 km의 누적 거리를 주행할 것으로 예측되고 있어서, 자율 주행 학습을 위한 데이터 수집의 양에 있어서 타회사들에과 비교할 수 없는 유리한 위치를 차지하고 있다. MIT의 AI연구자 Lex Fridman에 따르면 Waymo 같은 경우 자율주행을 개발하기 위해서 프로그램을 개발하고 일부 부분을 딥러닝을 이용하고 있다. 이에 반해서 테슬라는 모든 자율주행 관련된 기능이 딥러닝 그 자체로 이루어져 있다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeua18pxlNER",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}